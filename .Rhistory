leaders$result == "dies within a day after the attack"|
leaders$result == "dies, timing unknown", 1, 0)
leaders <- mutate(leaders, diff = polityafter - politybefore)
sd <- sd(leaders$polityafter)
xbar <- mean(leaders$polityafter, na.rm = TRUE)
# Step 1, find x bar (empircal mean)
xbar <- mean(leaders$polityafter, na.rm = TRUE)
# Step 2, find the standard deviation
sd <- sd(leaders$polityafter)
# Step 3, find the confidence level quantile
# input the confidence level, mean, and sd of the distribution, it will give you a number
quantile.value <- qnorm(0.95, xbar, sd)
# Step 4, build your CI
lwr <- xbar - (quantile.value*sd)
upr <- xbar + (quantile.value*sd)
ci <- c(lwr, upr)
ci
xbar <- mean(leaders$polityafter, na.rm = TRUE)
# Step 1, find x bar (empircal mean)
xbar <- mean(leaders$polityafter, na.rm = TRUE)
# Step 2, find the standard deviation & standard error
sd <- sd(leaders$polityafter)
se <- sd/sqrt(nrow(leaders))
# Step 3, find the confidence level quantile
# input the confidence level, mean, and sd of the distribution, it will give you a number
quantile.value <- qnorm(0.95, xbar, sd)
# Step 4, build your CI
lwr <- xbar - (quantile.value*se)
upr <- xbar + (quantile.value*se)
ci <- c(lwr, upr)
ci
# Step 1, find the z score
# The z score is a standardized value which can be mapped onto the normal distribution
z.score <- (xbar - 0)/sd
# Step 2, get the p-value for the z score
p.value <- pnorm(z.score, mean = 0, sd = sd)
# Step 1, find the z score
# The z score is a standardized value which can be mapped onto the normal distribution
z.score <- (xbar - 0)/sd
# Step 2, get the p-value for the z score
p.value <- pnorm(z.score, mean = 0, sd = sd)
# Step 1, find the z score
# The z score is a standardized value which can be mapped onto the normal distribution
z.score <- (xbar - 0)/sd
# Step 2, get the p-value for the z score
p.value <- pnorm(z.score, mean = xbar, sd = sd)
ifelse(p.value > 0.05, "Do not reject the null", "Reject the Null")
# Step 1, find the z score
# The z score is a standardized value which can be mapped onto the normal distribution
z.score <- (xbar - 0)/sd
# Step 2, get the p-value for the z score
# The p-value returns the area under the curve to the left (lower tail) of the z score
# Here I changed the defualt to return the upper tail
p.value <- pnorm(z.score, mean = xbar, sd = sd, lower.tail = F)
# Side note, here's a visual of what we just did
ggdistribution(dnorm, seq(-20, 20, 0.1), mean = xbar, sd = sd) +
geom_vline(xintercept = (qnorm(0.95, 0, 1)), colour = "blue") +
labs(title = "Plot of the PDF of the Normal Distribution",
subtitle = "Mean of -1.65 and Standard Deviation of 6.5") +
xlab("Value") +
ylab("Probability of Value Occuring") +
theme_light() +
annotate("text", x = - 1.7, y = 0.2, label = "0.05 \nQuantile") +
annotate("text", x = 1.7, y = 0.2, label = "0.95 \nQuantile") +
annotate("text", x = - 3.3, y = 0.07,
label = "5% of Observations \nlie under the curve") +
annotate("text", x = 3.3, y = 0.07,
label = "5% of Observations \nlie under the curve")
# Step 3, reject or do not reject the null hypothesis
# Here we want to find out whether the area to the left is less than or greater than
# 0.05 percent; if the p value is greater than 0.05 then we are less than
# 95% confident in our estimate
ifelse(p.value > 0.05, "Do not reject the null", "Reject the Null")
# Step 1, find the z score
# The z score is a standardized value which can be mapped onto the normal distribution
z.score <- (xbar - 0)/sd
# Step 2, get the p-value for the z score
# The p-value returns the area under the curve to the left (lower tail) of the z score
# Here I changed the defualt to return the upper tail
p.value <- pnorm(z.score, mean = xbar, sd = sd, lower.tail = F)
# Side note, here's a visual of what we just did
ggdistribution(dnorm, seq(-20, xbar, sd), mean = xbar, sd = sd) +
geom_vline(xintercept = (qnorm(0.95, xbar, sd)), colour = "blue") +
geom_vline(xintercept = (p.value), colour = "dark blue") +
labs(title = "Plot of the PDF of the Normal Distribution",
subtitle = "Mean of -1.65 and Standard Deviation of 6.5",
x = "Value", y = "Probability of Value Occuring") +
theme_light() +
annotate("text", x = p.value, y = 0.1, label = "P Value") +
annotate("text", x = 1.7, y = 0.2, label = "0.95 \nQuantile")
# Step 3, reject or do not reject the null hypothesis
# Here we want to find out whether the area to the left is less than or greater than
# 0.05 percent; if the p value is greater than 0.05 then we are less than
# 95% confident in our estimate
ifelse(p.value > 0.05, "Do not reject the null", "Reject the Null")
# Step 1, find the z score
# The z score is a standardized value which can be mapped onto the normal distribution
z.score <- (xbar - 0)/sd
# Step 2, get the p-value for the z score
# The p-value returns the area under the curve to the left (lower tail) of the z score
# Here I changed the defualt to return the upper tail
p.value <- pnorm(z.score, mean = xbar, sd = sd, lower.tail = F)
# Side note, here's a visual of what we just did
ggdistribution(dnorm, seq(-20, xbar, sd), mean = xbar, sd = sd) +
geom_vline(xintercept = (qnorm(0.95, xbar, sd)), colour = "blue") +
geom_vline(xintercept = (p.value), colour = "dark blue") +
labs(title = "Plot of the PDF of the Normal Distribution",
subtitle = "Mean of -1.65 and Standard Deviation of 6.5",
x = "Value", y = "Probability of Value Occuring") +
theme_light() +
annotate("text", x = p.value, y = 0.1, label = "P Value") +
annotate("text", x = 1.7, y = 0.2, label = "0.95 \nQuantile")
# Step 3, reject or do not reject the null hypothesis
# Here we want to find out whether the area to the left is less than or greater than
# 0.05 percent; if the p value is greater than 0.05 then we are less than
# 95% confident in our estimate
ifelse(p.value > 0.05, "Do not reject the null", "Reject the Null")
# Step 1, find the z score
# The z score is a standardized value which can be mapped onto the normal distribution
z.score <- (xbar - 0)/sd
# Step 2, get the p-value for the z score
# The p-value returns the area under the curve to the left (lower tail) of the z score
# Here I changed the defualt to return the upper tail
p.value <- pnorm(z.score, mean = xbar, sd = sd, lower.tail = F)
# Side note, here's a visual of what we just did
ggdistribution(dnorm, seq(-20, xbar, sd), mean = xbar, sd = sd) +
geom_vline(xintercept = (qnorm(0.95, xbar, sd)), colour = "blue") +
geom_vline(xintercept = (p.value), colour = "dark blue") +
labs(title = "Plot of the PDF of the Normal Distribution",
subtitle = "Mean of -1.65 and Standard Deviation of 6.5",
x = "Value", y = "Probability of Value Occuring") +
theme_light()
# Step 3, reject or do not reject the null hypothesis
# Here we want to find out whether the area to the left is less than or greater than
# 0.05 percent; if the p value is greater than 0.05 then we are less than
# 95% confident in our estimate
ifelse(p.value > 0.05, "Do not reject the null", "Reject the Null")
# Step 1, find the z score
# The z score is a standardized value which can be mapped onto the normal distribution
z.score <- (xbar - 0)/sd
# Step 2, get the p-value for the z score
# The p-value returns the area under the curve to the left (lower tail) of the z score
# Here I changed the defualt to return the upper tail
p.value <- pnorm(z.score, mean = xbar, sd = sd, lower.tail = F)
# Side note, here's a visual of what we just did
ggdistribution(dnorm, seq(-20, xbar, sd, 0.01), mean = xbar, sd = sd) +
geom_vline(xintercept = (qnorm(0.95, xbar, sd)), colour = "blue") +
geom_vline(xintercept = (p.value), colour = "dark blue") +
labs(title = "Plot of the PDF of the Normal Distribution",
subtitle = "Mean of -1.65 and Standard Deviation of 6.5",
x = "Value", y = "Probability of Value Occuring") +
theme_light()
# Step 1, find the z score
# The z score is a standardized value which can be mapped onto the normal distribution
z.score <- (xbar - 0)/sd
# Step 2, get the p-value for the z score
# The p-value returns the area under the curve to the left (lower tail) of the z score
# Here I changed the defualt to return the upper tail
p.value <- pnorm(z.score, mean = xbar, sd = sd, lower.tail = F)
# Side note, here's a visual of what we just did
ggdistribution(dnorm, seq(-20, 20, 0.01), mean = xbar, sd = sd) +
geom_vline(xintercept = (qnorm(0.95, xbar, sd)), colour = "blue") +
geom_vline(xintercept = (p.value), colour = "dark blue") +
labs(title = "Plot of the PDF of the Normal Distribution",
subtitle = "Mean of -1.65 and Standard Deviation of 6.5",
x = "Value", y = "Probability of Value Occuring") +
theme_light() +
annotate("text", x = p.value, y = 0.1, label = "P Value") +
annotate("text", x = 1.7, y = 0.2, label = "0.95 \nQuantile")
# Step 3, reject or do not reject the null hypothesis
# Here we want to find out whether the area to the left is less than or greater than
# 0.05 percent; if the p value is greater than 0.05 then we are less than
# 95% confident in our estimate
ifelse(p.value > 0.05, "Do not reject the null", "Reject the Null")
# Step 1, find the z score
# The z score is a standardized value which can be mapped onto the normal distribution
z.score <- (xbar - 0)/sd
# Step 2, get the p-value for the z score
# The p-value returns the area under the curve to the left (lower tail) of the z score
# Here I changed the defualt to return the upper tail
p.value <- pnorm(z.score, mean = xbar, sd = sd, lower.tail = F)
# Side note, here's a visual of what we just did
ggdistribution(dnorm, seq(-20, 20, 0.01), mean = xbar, sd = sd) +
geom_vline(xintercept = (qnorm(0.95, xbar, sd)), colour = "blue") +
geom_vline(xintercept = (p.value), colour = "dark blue") +
labs(title = "Plot of the PDF of the Normal Distribution",
subtitle = "Mean of -1.65 and Standard Deviation of 6.5",
x = "Value", y = "Probability of Value Occuring") +
theme_light() +
annotate("text", x = p.value, y = 0.1, label = "P Value") +
annotate("text", x = 9, y = 0.15, label = "0.95 \nQuantile")
# Step 3, reject or do not reject the null hypothesis
# Here we want to find out whether the area to the left is less than or greater than
# 0.05 percent; if the p value is greater than 0.05 then we are less than
# 95% confident in our estimate
ifelse(p.value > 0.05, "Do not reject the null", "Reject the Null")
# Step 1, find the z score
# The z score is a standardized value which can be mapped onto the normal distribution
z.score <- (xbar - 0)/sd
# Step 2, get the p-value for the z score
# The p-value returns the area under the curve to the left (lower tail) of the z score
# Here I changed the defualt to return the upper tail
p.value <- pnorm(z.score, mean = xbar, sd = sd, lower.tail = F)
# Side note, here's a visual of what we just did
ggdistribution(dnorm, seq(-20, 20, 0.01), mean = xbar, sd = sd) +
geom_vline(xintercept = (qnorm(0.95, xbar, sd)), colour = "blue") +
geom_vline(xintercept = (p.value), colour = "dark blue") +
labs(title = "Plot of the PDF of the Normal Distribution",
subtitle = "Mean of -1.65 and Standard Deviation of 6.5",
x = "Value", y = "Probability of Value Occuring") +
theme_light() +
annotate("text", x = p.value, y = 0.1, label = "P Value") +
annotate("text", x = 9, y = 0.05, label = "0.95 \nQuantile")
# Step 3, reject or do not reject the null hypothesis
# Here we want to find out whether the area to the left is less than or greater than
# 0.05 percent; if the p value is greater than 0.05 then we are less than
# 95% confident in our estimate
ifelse(p.value > 0.05, "Do not reject the null", "Reject the Null")
# Step 1, find the z score
# The z score is a standardized value which can be mapped onto the normal distribution
z.score <- (xbar - 0)/sd
# Step 2, get the p-value for the z score
# The p-value returns the area under the curve to the left (lower tail) of the z score
# Here I changed the defualt to return the upper tail
p.value <- pnorm(z.score, mean = xbar, sd = sd, lower.tail = F)
# Side note, here's a visual of what we just did
ggdistribution(dnorm, seq(-20, 20, 0.01), mean = xbar, sd = sd) +
geom_vline(xintercept = (qnorm(0.95, xbar, sd)), colour = "blue") +
geom_vline(xintercept = (p.value), colour = "dark blue") +
labs(title = "Plot of the PDF of the Normal Distribution",
subtitle = "Mean of -1.65 and Standard Deviation of 6.5",
xlab = "Value", ylab = "Probability of Value Occuring") +
theme_light() +
annotate("text", x = p.value, y = 0.1, label = "P Value") +
annotate("text", x = 9, y = 0.05, label = "0.95 \nQuantile")
# Step 3, reject or do not reject the null hypothesis
# Here we want to find out whether the area to the left is less than or greater than
# 0.05 percent; if the p value is greater than 0.05 then we are less than
# 95% confident in our estimate
ifelse(p.value > 0.05, "Do not reject the null", "Reject the Null")
# The standard normal has a mean of 0 and a SD of 1
# The theoretical PDF is
ggdistribution(dnorm, seq(-5, 5, 0.1), mean = 0, sd = 1) +
geom_vline(xintercept = (qnorm(0.95, 0, 1)), colour = "blue") +
geom_vline(xintercept = (qnorm(0.05, 0, 1)), colour = "dark blue") +
labs(title = "Plot of the Theoretical PDF of the Normal Distribution",
subtitle = "Mean of 0 and Standard Deviation of 1") +
xlab("Value") +
ylab("Probability of Value Occuring") +
theme_light() +
annotate("text", x = - 1.7, y = 0.2, label = "0.05 \nQuantile") +
annotate("text", x = 1.7, y = 0.2, label = "0.95 \nQuantile") +
annotate("text", x = - 3.3, y = 0.07,
label = "5% of Observations \nlie under the curve") +
annotate("text", x = 3.3, y = 0.07,
label = "5% of Observations \nlie under the curve")
# Step 1, find the z score
# The z score is a standardized value which can be mapped onto the normal distribution
z.score <- (xbar - 0)/sd
# Step 2, get the p-value for the z score
# The p-value returns the area under the curve to the left (lower tail) of the z score
# Here I changed the defualt to return the upper tail
p.value <- pnorm(z.score, mean = xbar, sd = sd, lower.tail = F)
# Side note, here's a visual of what we just did
ggdistribution(dnorm, seq(-20, 20, 0.01), mean = xbar, sd = sd) +
geom_vline(xintercept = (qnorm(0.95, xbar, sd)), colour = "blue") +
geom_vline(xintercept = (p.value), colour = "dark blue") +
labs(title = "Plot of the PDF of the Normal Distribution",
subtitle = "Mean of -1.65 and Standard Deviation of 6.5") +
xlab("Value") + ylab("Probability of Value Occuring") +
theme_light() +
annotate("text", x = p.value, y = 0.1, label = "P Value") +
annotate("text", x = 9, y = 0.05, label = "0.95 \nQuantile")
# Step 3, reject or do not reject the null hypothesis
# Here we want to find out whether the area to the left is less than or greater than
# 0.05 percent; if the p value is greater than 0.05 then we are less than
# 95% confident in our estimate
ifelse(p.value > 0.05, "Do not reject the null", "Reject the Null")
# Step 1, find the z score
# The z score is a standardized value which can be mapped onto the normal distribution
z.score <- (xbar - 0)/sd
# Step 2, get the p-value for the z score
# The p-value returns the area under the curve to the left (lower tail) of the z score
# Here I changed the defualt to return the upper tail
p.value <- pnorm(z.score, mean = xbar, sd = sd, lower.tail = T)
# Side note, here's a visual of what we just did
ggdistribution(dnorm, seq(-20, 20, 0.01), mean = xbar, sd = sd) +
geom_vline(xintercept = (qnorm(0.95, xbar, sd)), colour = "blue") +
geom_vline(xintercept = (p.value), colour = "dark blue") +
labs(title = "Plot of the PDF of the Normal Distribution",
subtitle = "Mean of -1.65 and Standard Deviation of 6.5") +
xlab("Value") + ylab("Probability of Value Occuring") +
theme_light() +
annotate("text", x = p.value, y = 0.1, label = "P Value") +
annotate("text", x = 9, y = 0.05, label = "0.95 \nQuantile")
# Step 3, reject or do not reject the null hypothesis
# Here we want to find out whether the area to the left is less than or greater than
# 0.05 percent; if the p value is greater than 0.05 then we are less than
# 95% confident in our estimate
ifelse(p.value > 0.05, "Do not reject the null", "Reject the Null")
# Step 1, find the z score
# The z score is a standardized value which can be mapped onto the normal distribution
z.score <- (xbar - 0)/sd
# Step 2, get the p-value for the z score
# The p-value returns the area under the curve to the left (lower tail) of the z score
# Here I changed the defualt to return the upper tail
p.value <- pnorm(z.score, mean = xbar, sd = sd, lower.tail = F)
# Side note, here's a visual of what we just did
ggdistribution(dnorm, seq(-20, 20, 0.01), mean = xbar, sd = sd) +
geom_vline(xintercept = (qnorm(0.95, xbar, sd)), colour = "blue") +
geom_vline(xintercept = (p.value), colour = "dark blue") +
labs(title = "Plot of the PDF of the Normal Distribution",
subtitle = "Mean of -1.65 and Standard Deviation of 6.5") +
xlab("Value") + ylab("Probability of Value Occuring") +
theme_light() +
annotate("text", x = p.value, y = 0.1, label = "P Value") +
annotate("text", x = 9, y = 0.05, label = "0.95 \nQuantile")
# Step 3, reject or do not reject the null hypothesis
# Here we want to find out whether the area to the left is less than or greater than
# 0.05 percent; if the p value is greater than 0.05 then we are less than
# 95% confident in our estimate
ifelse(p.value > 0.05, "Do not reject the null", "Reject the Null")
treat <- subset(leaders, success == 1)
control <- subset(leaders, success == 0)
treat.mean <- mean(treat$diff, na.rm = T)
joint.se <- sqrt((var(treat$diff)/nrow(treat)) +
(var(control$diff)/nrow(control)))
# Joint standard error
joint.se <- sqrt((var(treat$diff)/nrow(treat)) +
(var(control$diff)/nrow(control)))
# Difference in means
dim <- treat.mean - treat.control
# Joint standard error
joint.se <- sqrt((var(treat$diff)/nrow(treat)) +
(var(control$diff)/nrow(control)))
# Difference in means
dim <- treat.mean - control.mean
treat <- subset(leaders, success == 1)
control <- subset(leaders, success == 0)
treat.mean <- mean(treat$diff, na.rm = T)
control.mean <- mean(control$diff, na.rm = T)
treat.sd <- sd(treat$diff, na.rm = T)
control.sd <- sd(control$diff, na.rm = T)
treat.se <- treat.sd/sqrt(nrow(treat))
control.se <- control.sd/sqrt(nrow(control))
# Joint standard error
joint.se <- sqrt((var(treat$diff)/nrow(treat)) +
(var(control$diff)/nrow(control)))
# Difference in means
dim <- treat.mean - control.mean
# Find the quantile
q <- qnorm(0.95, dim, joint.se)
# Make the CI
lower <- dim - (joint.se*q)
upper <- dim + (joint.se*q)
ci <- c(lower, upper)
ci
# Get the z score
z.score.joint <- (dim - 0)/joint.se
# Find the p value
p.value.joint <- pnorm(z.score.joint, dim, joint.se, lower.tail = F)
# Check what's going on
ifelse(p.value.joint > 0.05, "Do not reject the null", "Reject the null")
knitr::opts_chunk$set(echo = TRUE)
# Joint standard error
joint.se <- sqrt((var(treat$diff)/nrow(treat)) +
(var(control$diff)/nrow(control)))
# Difference in means
dim <- treat.mean - control.mean
# Find the quantile
q <- qnorm(0.95, 0, 1)
# Make the CI
lower <- dim - (joint.se*q)
upper <- dim + (joint.se*q)
ci <- c(lower, upper)
ci
# Get the z score
z.score.joint <- (dim - 0)/joint.se
# Find the p value
p.value.joint <- pnorm(z.score.joint, 0, 1, lower.tail = F)
# Check what's going on
ifelse(p.value.joint > 0.05, "Do not reject the null", "Reject the null")
# Step 1, find the z score
# The z score is a standardized value which can be mapped onto the normal distribution
z.score <- (xbar - 0)/sd
# Step 2, get the p-value for the z score
# The p-value returns the area under the curve to the left (lower tail) of the z score
# Here I changed the defualt to return the upper tail
p.value <- pnorm(z.score, mean = 0, sd = 1, lower.tail = F)
# Side note, here's a visual of what we just did
ggdistribution(dnorm, seq(-20, 20, 0.01), mean = xbar, sd = sd) +
geom_vline(xintercept = (qnorm(0.95, xbar, sd)), colour = "blue") +
geom_vline(xintercept = (p.value), colour = "dark blue") +
labs(title = "Plot of the PDF of the Normal Distribution",
subtitle = "Mean of -1.65 and Standard Deviation of 6.5") +
xlab("Value") + ylab("Probability of Value Occuring") +
theme_light() +
annotate("text", x = p.value, y = 0.075, label = "P Value") +
annotate("text", x = 9, y = 0.05, label = "0.95 \nQuantile")
knitr::opts_chunk$set(echo = TRUE)
# p_load is a function in the pacman package which installs a package if haven't already and
# then calls it using the library() function
pacman::p_load(ggplot2, dplyr, wesanderson, ggfortify)
leaders <- read.csv("leaders.csv")
# Drop the first 14 empty columns
leaders <- leaders[(1:250), (15:28)]
leaders$success <- ifelse(leaders$result == "dies between a day and a week"|
leaders$result =="dies between a week and a month"|
leaders$result == "dies within a day after the attack"|
leaders$result == "dies, timing unknown", 1, 0)
leaders <- mutate(leaders, diff = polityafter - politybefore)
# The standard normal has a mean of 0 and a SD of 1
# The theoretical PDF is
ggdistribution(dnorm, seq(-5, 5, 0.1), mean = 0, sd = 1) +
geom_vline(xintercept = (qnorm(0.95, 0, 1)), colour = "blue") +
geom_vline(xintercept = (qnorm(0.05, 0, 1)), colour = "dark blue") +
labs(title = "Plot of the Theoretical PDF of the Normal Distribution",
subtitle = "Mean of 0 and Standard Deviation of 1") +
xlab("Value") +
ylab("Probability of Value Occuring") +
theme_light() +
annotate("text", x = - 1.7, y = 0.2, label = "0.05 \nQuantile") +
annotate("text", x = 1.7, y = 0.2, label = "0.95 \nQuantile") +
annotate("text", x = - 3.3, y = 0.07,
label = "5% of Observations \nlie under the curve") +
annotate("text", x = 3.3, y = 0.07,
label = "5% of Observations \nlie under the curve")
# The Theretical CDF is
ggdistribution(pnorm, seq(-5, 5, 0.1), mean = 0, sd = 1) +
labs(title = "CDF of the Normal Distribution",
subtitle = "Mean of 0 and Standard Deviation of 11") +
xlab("Value of Normal Distribution") +
ylab("Probability of Value Less Than or Equal to Occuring") +
theme_light() + geom_vline(xintercept = 0, colour = "dark blue") +
annotate("text", x = 2.75, y = 0.7,
label = "50% of Observations \n are greater than 0") +
annotate("text", x = - 2.75, y = 0.3,
label = "50% of Observations \n are less than 0")
# Step 1, find x bar (empircal mean)
xbar <- mean(leaders$polityafter, na.rm = TRUE)
# Step 2, find the standard deviation & standard error
sd <- sd(leaders$polityafter)
se <- sd/sqrt(nrow(leaders))
# Step 3, find the confidence level quantile
# input the confidence level, mean, and sd of the distribution, it will give you a number
quantile.value <- qnorm(0.95, xbar, sd)
# Step 4, build your CI ~ don't forget to use standard error not standard deviation
lwr <- xbar - (quantile.value*se)
upr <- xbar + (quantile.value*se)
ci <- c(lwr, upr)
ci
# Step 1, find the z score
# The z score is a standardized value which can be mapped onto the normal distribution
z.score <- (xbar - 0)/sd
# Step 2, get the p-value for the z score
# The p-value returns the area under the curve to the left (lower tail) of the z score
# Here I changed the defualt to return the upper tail
p.value <- pnorm(z.score, mean = 0, sd = 1, lower.tail = F)
# Side note, here's a visual of what we just did
ggdistribution(dnorm, seq(-20, 20, 0.01), mean = xbar, sd = sd) +
geom_vline(xintercept = (qnorm(0.95, xbar, sd)), colour = "blue") +
geom_vline(xintercept = (p.value), colour = "dark blue") +
labs(title = "Plot of the PDF of the Normal Distribution",
subtitle = "Mean of -1.65 and Standard Deviation of 6.5") +
xlab("Value") + ylab("Probability of Value Occuring") +
theme_light() +
annotate("text", x = p.value, y = 0.075, label = "P Value") +
annotate("text", x = 9, y = 0.05, label = "0.95 \nQuantile")
# Step 3, reject or do not reject the null hypothesis
# Here we want to find out whether the area to the left is less than or greater than
# 0.05 percent; if the p value is greater than 0.05 then we are less than
# 95% confident in our estimate
ifelse(p.value > 0.05, "Do not reject the null", "Reject the Null")
treat <- subset(leaders, success == 1)
control <- subset(leaders, success == 0)
treat.mean <- mean(treat$diff, na.rm = T)
control.mean <- mean(control$diff, na.rm = T)
treat.sd <- sd(treat$diff, na.rm = T)
control.sd <- sd(control$diff, na.rm = T)
treat.se <- treat.sd/sqrt(nrow(treat))
control.se <- control.sd/sqrt(nrow(control))
# Joint standard error
joint.se <- sqrt((var(treat$diff)/nrow(treat)) +
(var(control$diff)/nrow(control)))
# Difference in means
dim <- treat.mean - control.mean
# Find the quantile
q <- qnorm(0.95, 0, 1)
# Make the CI
lower <- dim - (joint.se*q)
upper <- dim + (joint.se*q)
ci <- c(lower, upper)
ci
# Get the z score
z.score.joint <- (dim - 0)/joint.se
# Find the p value
p.value.joint <- pnorm(z.score.joint, 0, 1, lower.tail = F)
# Check what's going on
ifelse(p.value.joint > 0.05, "Do not reject the null", "Reject the null")
# Step 1, find x bar (empircal mean)
xbar <- mean(leaders$polityafter, na.rm = TRUE)
# Step 2, find the standard deviation & standard error
sd <- sd(leaders$polityafter)
se <- sd/sqrt(nrow(leaders))
# Step 3, find the confidence level quantile
# input the confidence level, mean, and sd of the distribution, it will give you a number
quantile.value <- qnorm(0.95, 0, 1)
# Step 4, build your CI ~ don't forget to use standard error not standard deviation
lwr <- xbar - (quantile.value*se)
upr <- xbar + (quantile.value*se)
ci <- c(lwr, upr)
ci
