---
title: "Regression and Predicted Values"
author: "Marie Fester"
date: '2019-03-11'
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
pacman::p_load(ggplot2, dplyr, wesanderson, texreg)

leaders <- read.csv("leaders.csv")
```

# Recoding

Here I make a new variable called success, 1 indicates that the assassination was success (leader dies), and 0 means the attempt was not successful. Then I make a variable which is the difference between the polity scores before and after assassination attempts.
```{r}
leaders$success <- ifelse(leaders$result == "dies between a day and a week"| 
                                 leaders$result =="dies between a week and a month"| 
                                 leaders$result == "dies within a day after the attack"|
                                 leaders$result == "dies, timing unknown", 1, 0)

leaders <- mutate(leaders, diff = polityafter - politybefore)
```


# Regression

We can consider the hypothesis that a successful assassination will lead to a better polity score. Essentially, bad leaders are assassinated and replaced with new, better regimes. The base model predicts the difference in polity score before and after the attempt using the success variable. We can then add age of the ruler, and last we can add an interaction term between success and age of ruler.
```{r}
# Use the lm function to do a regression
# Place one variable on the left of the ~, it is your outcome or dependent variables
# The variables to the right are the independent variables; they predict the outcome variable 
model1 <- lm(diff ~ success, data = leaders)
model2 <- lm(diff ~ success + age, data = leaders)
model3 <- lm(diff ~ success * age + region + decade, data = leaders)

# Two different ways to visualize your regression

# screenreg() is a function from the texreg package; it is useful for showing multiple models that use
# the same outcome variable
screenreg(list(model1, model2, model3), custom.model.names = c("Basic Model", "Model 2", "Full Model"))

# summary calls all the information
# Estimate is the effect of the independent variable on the dependent variable
# Standard deviation is the distance from the estimate approcximately 50% of observations are within

summary(model2)
```

None of the independent variables have statistically signficant effects on the change in polity scores before and after an assasination attempt.

What about model fit? The adjusted r-squared is very low, which means that not much is being explained by the model. The residual standard error is low which is good, however, in this instance it is likely because there is little variation in pre and post assassination attempt values.

A quick note on factor variables. In this regression we used the category region as a variable, how does r calculate the effect of region? It compares each category to a base category, it chooses the default based on alphabetical order. In each case, the region is compared to Australia and New Zealand.

# Predicted Values
```{r}
# We add three new columsn to the leaders dataset, for the estimate, and the lower and upper bounds
# of the confidence interval (based on the standard deviation)
# we use the predict function, calling the model, then the dataset to draw values from
# set interval = confidence; the default is the 95% confidence interval
leaders[, c("fit", "lwr", "upr")] <- predict(model3, leaders, interval = "confidence")

```

## Plot 'em

Next up we want to visualize the predicted values, I show an example here in ggplot, but you can also use base r to plot them. For more examples of plots, check out the last tutoring handout on timeseries and histograms.

```{r}
# The first layer plots the actual values
ggplot(leaders, aes(x = year, y = diff, color = as.factor(success))) + geom_point() +
  labs(title = "Change in Polity Score in Countries with Leader Assassination Attempt, by Year",
       x = "Year", y = "Post - Pre Polity Score", color = "Success of \n Attmept", 
       subtitle = "Actual Values are Circles, Predicted Values are Triangles") +
# here I add another layer of geom_point, I set inherit.aes = FALSE so that it does not use the same 
# aesthetics as it did in the first layer, I give the points a different shape to see the difference
# between our predicted and actual data
  geom_point(inherit.aes = FALSE, data = leaders, 
             mapping = aes(x = year, y = fit, color = as.factor(success)), shape = 17, size = 2.5)
```


Overall, the data is clustered around 0, there are ibservation where the polity increase a lot and also ones with large derceases after an assassination attempt, no matter success. We see that success does seem to have an effect on polity scores; success is not sorted to either side of 0. There are many more unsuccessful attempts. The predicted values are less noisy; there is much less variation, this is because the predicted values are based on a model which makes estimates based on the average data point.




